# Entity Linking 
This document serves as a guide for creating datasets used for Entity Linking.

## Overview
The dataset used for Entity Linking consists of a dictionary of entities in the `.json` format and `train.jsonl`, `val.jsonl`, and 
`test.jsonl` files containing questions for training, validation and testing respectively. The questions are generated randomly by combining domain entity names and manually written question templates. Please refer to the 
[Entity Linking Training Readme](../../Training/EntityLinking/readme.md) for more details on Training.

## Setup
Install `Python 3.8`

### Required Files
1. Follow the steps outlined in the [Required Files section of the main README](../../readme.md#required-files) by creating a `DATA` folder under `MARIE_AND_BERT` and unzip `Dictionaries.zip` and `EntityLinking.zip` into the `DATA` folder.
2. Copy `pubchemwithSMILE.jsonl` from `DATA/EntityLinking/training_files_generation` into `DATA/KGToolbox/EntityLinking`.
3. Copy all the files from `DATA/EntityLinking/training_files_generation/templates` into `DATA/KGToolbox/EntityLinking/templates`.

`DATA/EntityLinking/training_files_generation/examples` contains example files that can be referred to for checking the expected 
format of output files.

## Running
To create a dataset for the Entity Linking model, follow the steps outlined below:

### Create Entity Dictionaries

Generate a dictionary of entities for each ontology using:
```
python generateEntityDictJPS.py --infile ./DATA/Dictionaries/ontokin/name_dict.json  --outfile ./ontokin.json
```
* `--infile`  orginal name_dict file in DATA/Dictionaries for the ontology
* `--outfile` path to save output file

See `DATA/EntityLinking/training_files_generation/examples/ontokin.json` for an example output format of entity dictionary for ontokin.

### Create Question Files
#### 1. For SMILES-NER:

Generate the `train/val/test.jsonl` SMILES question files by running the following:
```
python generateFromTemplate.py \
 --outfile train.jsonl \               #path to save output jsonl file
 --mode train \                        #['test'/'val'/'train']
 --question_type smiles \              #["general"/"smiles"]
 --question_num 1000 \                 #number of questions to generate
 --seed 0                              #random seed
```
* `--outfile` Path to save output jsonl file.
* `--mode` ['test'/'val'/'train']. Test and run/valid uses separate templates for evaluation purpose.
* `--question_type` ["general"/"smiles"]. Question with smile strings or general entities.
* `--question_num` Number of questions to be generated in the file. 
* `--seed` Random seed. It is recommended to use different seed for individual mode.

#### 2. For General Entity Extraction: 

Run the following command to generate the <b>raw</b> `train/val/test.jsonl` question files for each ontology:

Example:
```
python generateFromTemplate.py \
--infile ontokin.jsonl \               #path to Domain Entity Dictionary
 --outfile test_raw.jsonl \            #path to save output jsonl file
 --mode train \                        #['test'/'val'/'train']
 --question_type general \              #["general"/"smiles"]
 --question_num 10000 \                 #number of questions to generate
 --seed 0
```
* `--infile` path of the respective domain entity dictionary generated in the [Entiity Dictionaries](#entity-dictionary) step.
* For other parameters, refer to [SMILES-NER](#1.-for-smiles-ner:) step

##### 2.1 Generate the `train/val/test.jsonl` question files required for the first step of Entity Extraction Training:

Run `convertQuestionBlinkFormat.py` to convert the raw outfile generated [above](#2-for-general-entity-extraction) (e.g., `test_raw.jsonl`) to the accepted format. 

Set the `convert_type` parameter to `blink`.

Example:
```
python convertQuestionBlinkFormat.py \
--infile test_raw.jsonl \             # input file path
--outfile test.jsonl \                # output file path
--convert_type blink                  # ["blink"/"elq"]
```
* `--infile` Path to input raw question file generated by [above](#2-for-general-entity-extraction) step.
* `--outfile` Path to save output formatted question file.
* `--convert_type` ["general"/"smiles"]. Whether converting to blink(1st step) format or elq(2nd step) format. 

See `DATA/EntityLinking/training_files_generation/examples/ontokin_blink_format_example.jsonl` for an example of an expected output file.


##### 2.2. Generate the `train/test/valid.jsonl` question files required for the second step of Entity Extraction Training:   

Run `convertQuestionBlinkFormat.py` to convert the raw outfile generated [above](#2-for-general-entity-extraction) (e.g., `test_raw.jsonl`) to the accepted format.

Set the `convert_type` parameter to `elq` for second step dataset.

Example:
```
python convertQuestionBlinkFormat.py \
--infile test_raw.jsonl \             # input file path
--outfile test.jsonl \                # output file path
--convert_type elq                    # ["blink"/"elq"]
```
* For parameters, refer to [2.1](#2.1.Generate-the-train/val/test.jsonl-question-files-required-for-the-first-step-of-Entity-Extraction-Training).

See `DATA/EntityLinking/training_files_generation/examples/ontokin_elq_format_example.jsonl` for an example of an expected output file.
## Overview
Two models are trained for EL:
1. A SMILES-NER model for smiles string recognition and translation module
2. The Entity Extraction module. We use the method of BLINK project: https://github.com/facebookresearch/BLINK.

## Setup
1. Import the BLINK project from https://github.com/facebookresearch/BLINK. The customized files in `Training/EntityLinking` should be put in the top level directory of the BLINK project.
2. Install Python 3.8 and Run `pip install requirements.txt`. It is recommended to use conda for creating a virtual environment. Note that this can share the same environment with the whole Marie project and does not necessarily need separate environment.


## Data Preparation
1. SMILES-NER needs a trio of train/valid/test|jsonl files.
2. Entity Extraction(BLINK) uses a two-step process. First step needs an entity dictionary |jsonl and a trio of train/valid/test|jsonl. Second steps needs another trio of train/valid/test |jsonl which is of slightly different format.
Regarding the creation of these files, please see `MARIE_AND_BERT/KGToolbox/EntityLinking/readme.md`.

##Folder Structure
<pre>
├── blink-project-files...
├── trainbi.py    #Customized entry point to run BLINK training
├── evalbi.py     #Customized entry point to run BLINK evaluation
└── translator    # NER training code
    ├── util.py
    ├── train.py  #Entry point for NER train
    └── test.py   #Entry point for NER eval
└── my_scripts
    ├── train_entity_encoder.sh
    ├── train_question_encoder.sh
    └── train_ner.sh
</pre>

## Train NER
```
bash train_ner.sh [valid_file_name] [train_file_name]
```
Arguments can be supplied when calling bash to change I/O paths. Aftering run, the model is saved to the specified path (default is `./models/ner/SMILES_NER.bin`)  
* `--valid_file_name` Path to valid file.
* `--train_file_name` Path to train file.

## Train Entity Extraction
Entity Extraction training needs two steps.
First step:
```
bash train_entity_encoder.sh [data_path] [output_path]
```
To customize the I/O directorys:
* `--data_path` Path to first step data files. Suggested is `data/step1`.
* `--output_path` Path to output (step1) folder. Suggested is `models/step1`.


--path_to_model models/pretrain/pytorch_model.bin --data_path data/pretrain --output_path models/pretrain

Second step:
```
bash train_question_encoder.sh [path_to_first_step_out] [data_path] [output_path]
```
* `--path_to_first_step_out` Path to output folder of step1. Suggested is `data/step1`.
* `--data_path` Path to second step data files. Suggested is `data/step2`.
* `--output_path` Path to output (step2) folder. Suggested is `models/step2`.




For example, the input folders are `./data/step1` for the first step and `./data/step2` for the second step; default output folders are `./models/step1` and `./models/step2` respectively.
Below would be an example of the default i/o structure. Files marked with # are input files; files marked with * are generated by the training process and are the final binary files required for Marie system running, which should be put under DATA/EntityLinking in the main project. Refer to MARIE_AND_BERT/readme.md to download an example of EntityLinking binary files. 
<pre>
├── project-files...
├── data
    ├── step1
         ├── dict.jsonl#
	 ├── train.jsonl#
	 ├── valid.jsonl#
    	 └── test.jsonl#
    ├── step2
         ├── dict.jsonl#
	 ├── train.jsonl#
	 ├── valid.jsonl#
    	 └── test.jsonl#
    └── ner
	 ├── train.jsonl#
	 ├── dev.jsonl#
    	 └── test.jsonl#
└── models
    ├── step1
         ├── ...
	 ├── id2text.json*
	 ├── id2title.json*
	 ├── id2wikidata.json*
    	 └── embeddingbase.pt*
    ├── step2
         ├── ...
	 ├── pytorch_model.bin*
    	 └── training_params.txt*
    └── ner
         └── SMILES_NER.bin*
</pre>

The location of these files in EntityLinking.zip are:
<pre>
├── EntityLinking
    ├── ...
    ├── models
         ├── id2text.json
         ├── id2title.json
         └── id2wikidata.json
    ├── pytorch_model.bin
    ├── embeddingbase.pt
    ├── training_params.txt
    └── SMILES_NER.bin*

</pre>
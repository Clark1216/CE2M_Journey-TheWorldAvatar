## Overview
Two models are trained for EL:
1. A SMILES-NER model for smiles string recognition and translation module
2. The Entity Extraction module. We use the method of BLINK project: https://github.com/facebookresearch/BLINK.

## Setup
1. Clone the BLINK project from https://github.com/facebookresearch/BLINK. All the files in `Training/EntityLinking` should be put in the top level directory of the BLINK project.
2. Install Python 3.8 and Run `pip install requirements.txt`. It is recommended to use conda for creating a virtual environment. Note that this can share the same environment with the whole Marie project and does not necessarily need separate environment.


## Data Preparation
1.Regarding the creation of training files, please see `MARIE_AND_BERT/KGToolbox/EntityLinking/readme.md`.
2. Put three sets of training files into separate folders. For example, `data/step1`, `data/step2`,`data/ner`.


##Folder Structure
After setup and data preparation, the folder should look like this:
<pre>
├── blink-project-files...
├── trainbi.py    #Customized entry point to run BLINK training
├── evalbi.py     #Customized entry point to run BLINK evaluation
└── translator    # NER training code
    ├── util.py
    ├── train.py  #Entry point for NER train
    └── test.py   #Entry point for NER eval
└── my_scripts
    ├── train_entity_encoder.sh
    ├── train_question_encoder.sh
    └── train_ner.sh
├── data
    ├── step1
         ├── dict.jsonl#
         ├── train.jsonl#
         ├── valid.jsonl#
    	 └── test.jsonl#
     ├── step2
         ├── dict.jsonl#
         ├── train.jsonl#
         ├── valid.jsonl#
    	 └── test.jsonl#
     └── ner
         ├── train.jsonl#
         ├── dev.jsonl#
         └── test.jsonl#
</pre>

## Train SMILES-NER
```
bash train_ner.sh [valid_file_name] [train_file_name] [output_path]
```

* `--valid_file_name` Path to SMILES valid file.
* `--train_file_name` Path to SMILES training file.
* `--output_path` Path to output SMILES-NER model.

## Train Entity Extraction
Entity Extraction training needs two steps.
First step:
```
bash train_entity_encoder.sh [data_path] [output_path]
```
* `--data_path` Path to first step data files. Suggested is `data/step1`.
* `--output_path` Path to output (step1) folder. Suggested is `models/step1`.


Second step:
```
bash train_question_encoder.sh [path_to_first_step_out] [data_path] [output_path]
```
* `--path_to_first_step_out` Path to output folder of step1. Suggested is `data/step1`.
* `--data_path` Path to second step data files. Suggested is `data/step2`.
* `--output_path` Path to output (step2) folder. Suggested is `models/step2`.


Below would be an example of the i/o structure after running the training. Files marked with * are generated by the training process and are the final binary files required for Marie system running, which should be put under DATA/EntityLinking in the main project. Refer to MARIE_AND_BERT/readme.md to download an example of EntityLinking binary files. 
<pre>
├── project-files...
├── data
└── models
    ├── step1
         ├── ...
         ├── id2text.json*
	     ├── id2title.json*
	     ├── id2wikidata.json*
    	 └── embeddingbase.pt*
    ├── step2
         ├── ...
         ├── pytorch_model.bin*
    	 └── training_params.txt*
    └── ner
         └── SMILES_NER.bin*
</pre>

The location of these files in DATA/EntityLinking are:
<pre>
├── EntityLinking
    ├── ...
    ├── models
         ├── id2text.json
         ├── id2title.json
         └── id2wikidata.json
    ├── pytorch_model.bin
    ├── embeddingbase.pt
    ├── training_params.txt
    └── SMILES_NER.bin*

</pre>
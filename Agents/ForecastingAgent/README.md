# Forecasting Agent

This `Forecasting Agent` can be used to predict instantiated time series from The World Avatar (TWA), and instantiate the forecasts back into the knowledge graph (KG) using the [OntoTimeSeries] ontology. Reading and writing time series from/into the KG relies on the [TimeSeriesClient].

As of version `2.0.0` the agent is implemented using the [Derived Information Framework]'s (DIF) `DerivationWithTimeSeries` concept to ensure proper data provenance. The required input instances to derive a forecast are described in the [required derivation markup](#13-required-derivation-markup) section below. The agent is designed to be deployed as a Docker container and can be deployed either as standalone version or as part of a larger Docker stack.

The Python library [Darts] is used to create the forecasts (and similarly to define, train, and store forecasting models). It contains a variety of models, from classics such as ARIMA over Facebook's Prophet to deep neural networks and transformers.


&nbsp;
# 1. Setup

This section specifies the minimum requirements to build and deploy the Docker image. 

## 1.1 Agent settings

The dockerised agent can be deployed as "standalone" version (i.e., outside a larger Docker stack) or deployed to an (existing) stack. Several key environment variables need to be set in the
- [docker compose file] for "standalone" deployment
- [stack manager input config file] for deployment using the [Stack manager]

```bash
OVERWRITE_FORECAST            # Boolean flag whether to overwrite data of existing forecast instance or create new one when updating forecast/derivation
ROUNDING                      # Number of wanted decimal places (int) of forecast values (optional)

#--- Deployment specific parameters ---#
# Required for Stack deployment (can be left blank for "standalone" deployment)
STACK_NAME                    # Will be set automatically when deployed via stack-manager
NAMESPACE                     # Blazegraph namespace (within Stack) to monitor
DATABASE                      # PostGIS/PostgreSQL database name (default: `postgres`)
# Required for "standalone" deployment (can be left blank for Stack deployment)
STACK_NAME                    # to be left blank for "standalone" deployment
DB_URL                        # PostGIS/PostgreSQL URL
DB_USER                       # PostGIS/PostgreSQL username
DB_PASSWORD                   # PostGIS/PostgreSQL password

#--- Derivation Agent parameters ---#
SPARQL_QUERY_ENDPOINT         # SPARQL endpoint to monitor/update
SPARQL_UPDATE_ENDPOINT        # SPARQL endpoint to monitor/update
ONTOAGENT_SERVICE_IRI         # IRI of OntoAgent service
ONTOAGENT_OPERATION_HTTP_URL  # Port needs to match port specified in `docker-compose.yml`
DERIVATION_INSTANCE_BASE_URL  # Base IRI of all instanced generated by agent
DERIVATION_PERIODIC_TIMESCALE # Interval in which to check for updated KG information (in s)
                              # (irrelevant as Forecasting Agent uses synchronous derivations only)
REGISTER_AGENT                # Boolean flag whether to register agent in KG (`true` required to detect derivations)
# Required inputs for DerivationAgent to start, although not relevant for ForecastingAgent (i.e., shall be left blank)
KG_USERNAME
KG_PASSWORD
FILE_SERVER_ENDPOINT
FILE_SERVER_USERNAME
FILE_SERVER_PASSWORD
```

The `STACK_NAME` variable is used to identify the deployment mode of the agent: In case the `STACK_NAME` is left blank, Postgres and Blazegraph endpoint settings will be taken from the `docker-compose file` values. Otherwise they will be retrieved using the StackClients based on the provided `NAMESPACE` and `DATABASE` variables.

Please note: 
- The `DB_URL` is optional as the agent will first try to retrieve the database endpoint instantiated for the time series IRI to forecast from the KG (and only use the specified environment variable as fallback)
- When deployed via the Stack manager, the `STACK_NAME` environment variable is set automatically and can be omitted in the config file
- `SPARQL_QUERY_ENDPOINT` and `SPARQL_UPDATE_ENDPOINT` are both required inputs even for stack deployment (due to default derivation agent config); however, as the actual values for initialising the Forecasting Agent are retrieved via the Stack clientsm they can be left blank.

## 1.2 Miscellaneous

**Only relevant** if you intend to build (and publish) the Docker image:

- Ensure access to CMCL Docker registry: 
    The required `stack-clients-*.jar` resource to be added to [py4jps] during building the Docker image is retrieved from the Stack-Clients docker image published on `docker.cmclinnovations.com`. Hence, access to the CMCL Docker registry is required from the machine building the agent image. For more information regarding the registry, see the [CMCL Docker registry wiki page].

- Ensure access to Github container registry:
    A `publish_docker_image.sh` convenience script is provided to build and publish the agent image to the [Github container registry]. To publish a new image, your github user name and [personal access token] (which must have a `scope` that [allows you to publish and install packages]) needs to be provided. 

If you intend to use a forecasting model pre-trained with [Darts]: Please be aware of potential issues when loading the model, in case of version clashes between the current environment and the one used for training.

## 1.3 Required derivation markup

Before any forecast can be created (and instantiated), all corresponding inputs need to be properly instantiated. This includes:
- `owl:Thing`: Instance to be forecasted (most likely `om:Measure` instance, but kept general)
- `ts:ForecastingModel`: Forecasting model to be used (i.e., Prophet, pre-trained transformer, ...)
- `ts:Frequency`: Frequency of the forecast (i.e., spacing of time steps)
- `time:Interval`: Interval to forecast (i.e., defining start and end time)
- `time:Duration`: Historical data length to use (i.e., duration prior to start time to use for model fitting and/or scaling of data for pre-trained models)

Used namespaces:
```xml
om    : http://www.ontology-of-units-of-measure.org/resource/om-2/
owl   : http://www.w3.org/2002/07/owl#
rdf   : http://www.w3.org/1999/02/22-rdf-syntax-ns#
rdfs  : http://www.w3.org/2000/01/rdf-schema#
xsd   : http://www.w3.org/2001/XMLSchema#
time  : http://www.w3.org/2006/time#
ts    : https://www.theworldavatar.com/kg/ontotimeseries/
deriv : https://www.theworldavatar.com/kg/ontoderivation/
```

Required forecast derivation inputs:
```xml
###   Required inputs   ###
<IRI_to_forecast> rdf:type owl:Thing ; 
                  ts:hasTimeSeries <IRI_of_time_series> . 
<IRI_of_time_series> rdf:type ts:TimeSeries ; 
                     ts:hasRDB <Postgres_URL> . 
<IRI_of_forecasting_model> rdf:type ts:ForecastingModel ; 
                           rdfs:label <Model_name> . 
<IRI_of_interval_to_forecast> rdf:type time:Interval ; 
                              time:hasBeginning <IRI_of_start_time_instant> ; 
                              time:hasEnd <IRI_of_end_time_instant> .
<IRI_of_forecast_frequency> rdf:type ts:Frequency .
<IRI_of_historical_data_length> rdf:type time:Duration .

# All time Instants needs to be represented as follows
<IRI_of_time_instant> rdf:type time:Instant ; 
                      time:inTimePosition <IRI_of_time_position> .
<IRI_of_time_position> rdf:type time:TimePosition ; 
                       time:numericPosition <xsd:decimal> ;
                       time:hasTRS <http://dbpedia.org/resource/Unix_time> .

# Both Frequency and Duration need to be represented as follows
<IRI_of_Duration> time:numericDuration <xsd:decimal> ;
                  ts:unitType <time:unitHour> .
# Alternative unit concepts: time:unitDay, time:unitMinute, time:unitSecond, ...


###   Optional inputs   ###
<IRI_to_forecast> om:hasUnit <IRI_of_OM_unit> . 
<IRI_of_forecasting_model> ts:scaleData <xsd:boolean> ;
                           ts:hasModelURL <model_path_link> ;
                           ts:hasCheckpointURL <model_chkpt_link> ;
                           ts:hasCovariate <IRI_of_covariate> . 
<IRI_of_covariate> rdf:type owl:Thing ; 
                   ts:hasTimeSeries <IRI_of_time_series> . 
<IRI_of_forecast_frequency> ts:resampleData <xsd:boolean> .
```

<!-- 
## 2.1 General workflow

This section describes the workflow and most important steps to access and extent the agent.
The Agent UML diagram provides an overview of how the agent works:

<p align="center">
    <img src="https://lucid.app/publicSegments/view/2f775ad5-4445-4036-8965-0021df53f6d9/image.png" alt="drawing" width="500"/>
</p>

The `Forecasting Agent` forecasts an existing time series in an KG using its `iri`. After verifying the received HTTP request, the agent loads a model configuration from the [mapping file]. This is either the `DEFAULT` one (which will use [Prophet]) or else must be specified with the `use_model_configuration` parameter in the HTTP request to use a pre-trained model other than Prophet. The [mapping File ] describes in detail what a model configuration `dict` consists of. 

Next the agent loads the time series (+ `covariates` if `load_covariates_func` is given in the loaded configuration) with the TSClient. 

Then, it loads the model. This is either a pre-trained model specified in the model configuration with the model link `model_path_pth_link` and the checkpoint link `model_path_ckpt_link` or else a new Prophet model is fitted to predict the data. The forecast starts from the optional parameter `forecast start date` in the request or if not specifed the last available date is taken. The forecast lasts over the number of specified time steps (`horizon`).

Finally the forecasted time series is instantiated. For that purpose a new `forecast iri` is created and attached to the `iri` specified in the request. Further metadata, e.g. which data and models are used, are included as well using the [OntoTimeSeries] ontology. -->

&nbsp;
# 3. Using the Agent

## 3.1 Building the Agent

To build and publish the agent Docker image please use the following commands. Please note that both commands are bundled in the  `publish_docker_image.sh` convenience script.

```bash
# Building the (production) image
docker compose -f docker-compose.yml build
# Publish the Docker image to the Github container registry
docker image push ghcr.io/cambridge-cares/<image tag>:<version>
```

Time out issues have been observed when building the image. If this happens, please try pulling the required stack-clients image first by `docker pull docker.cmclinnovations.com/stack-client:1.6.2`.

## 3.2 Deploying the Agent

It is recommended to pull the published Docker image from [Github container registry] for sole deployment (i.e., in case no modifications to the agent are needed):

```bash
# Pull published (production) image
docker pull ghcr.io/cambridge-cares/forecasting_agent:2:0:0
```

###  **Standalone Deployment**

Deploy the dockerised agent by running the following command from the same location where this README is located (ideally, use a bash terminal to avoid potential issues with inconsistent path separators). 

```bash
# Deploy the Docker image locally
docker compose -f docker-compose.yml up
```

To verify the correct startup of the agent, open the URL address the agent is running on, e.g., `http://localhost:5001/` in your browser. 


### **Stack Deployment**

If you want to spin up this agent as part of a stack, do the following:
1) Build OR pull the (production) image using the commands provided above (do not spin up the image)
2) Copy the `forecasting-agent.json` file from the [stack-manager-input-config] folder into the `inputs/config/services` folder of the stack manager
3) Start the stack manager as usual (i.e. `bash ./stack.sh start <STACK_NAME>` from the stack-manager repo). This should start the container. Please use a bash terminal to avoid potential issues with inconsistent path separators.
4) The agent shall become available at `http://<HOST>:<PORT>/forecastingAgent/`


## 3.3 Notes on Debugging

To debug the agent within the stack, follow these steps (similar)

1) Overwrite command specified in Dockerfile by providing `tail -f /dev/null` `Command` in stack-manager config file (this keeps the container alive indefinitely while doing nothing). An amended `forecasting-agent_debug` config is provided in the [stack-manager-input-config] folder.
2) Start stack-manager as usual
3) Right click on running agent container -> select "Attach Visual Studio Code"
4) Install required VSCode extensions inside the container
5) Start local debugging session inside container by running `entry_point.py` in debug mode; if HTTP requests from outside do not reach the container, send requests locally from inside the container as workaround


<!-- &nbsp;
## 2.4 Forecasting time series via HTTP requests

Forecasting a time series is triggered by receiving an HTTP `POST` request with a JSON body. An example request to forecast an `iri` is provided in [HTTP_Request_forecast]: 

### HTTP request parameters

- **iri**: the `iri` of the instance which has a time series attached to it. This `iri` will receive the `hasForecastedValue` relationship
- **horizon**: the number of time steps to forecast autorecursively into the future
- **forecast_start_date**: the start `dateTime` of the forecast. If not specified, simply the last value is taken as a starting point. The series is split at this point and future available data is used to calculate the forecasting error
- **data_length**: the number of values loaded before `forecast_start_date`. This data is used directly as input to fit [Prophet] or to scale the input for the pre-trained neural network (If not set the default value from the [mapping file] is used)
- **use_model_configuration**: if specified this model configuration from the [mapping file] is used

Further optional parameters can be provided to specify the connection configurations to use. All specified parameters overwrite potential default values specified in the docker-compose file. To use the default values, simply exclude the respective parameter from the HTTP request:
- **namespace**: target Blazegraph namespace (only relevant for Stack deployment)
- **database**: target PostGIS database (only relevant for Stack deployment)
- **query_endpoint**: SPARQL query endpoint (only relevant for standalone deployment)
- **update_endpoint**: SPARQL update endpoint (only relevant for standalone deployment)
- **db_url**: PostGIS/PostgreSQL database URL (only relevant for standalone deployment)
- **db_user**: PostGIS/PostgreSQL database user (only relevant for standalone deployment)
- **db_password**" PostGIS/PostgreSQL database password (only relevant for standalone deployment)


## 2.5 Custom model configurations and new models
Specify your custom configurations following the example of the `TFT_HEAT_SUPPLY` model configuration in the [mapping file]. 

If you need covariates, define a function which load them (similarly to `get_covs_heat_supply`) for the `load_covariates_func` parameter in your configuration. To use your own pre-trained model with [Darts], expand the [agent module] where `load_pretrained_model` is called just like the model for `TFT_HEAT_SUPPLY` is loaded. You can use the function `load_pretrained_model` as well if thats suits your model, just specify your model class and set the `input_length` as for `TFT_HEAT_SUPPLY`.  -->

&nbsp;
# 4. Dockerised agent tests

Both dockerised unit and integration tests are provided. Tests check for expected behaviour of the forecasting agents with and without overwriting existing forecasts. Hence, 4 containers will be created when running the tests:
- Forecasting Agent, which overwrites existing forecasts when creating new ones
- Forecasting Agent, which does not overwrite existing forecasts (this container also runs pytest)
- Blazegraph and Postgis instances (spun up via Docker in Docker using testcontainers)

```bash
# Build and run dockerised agent tests
docker compose -f "docker-compose-test_dockerised.yml" up -d --build
```

To run the dockerised tests in Debug mode, please run the below script to start up both testing agents and pytest in separate containers (to allow for debugging of the overwriting/non-overwriting forecasting agent versions separately). Subsequently, attach the Debugger(s) using the provided `Python: Debug dockerised tests` and `Python: Debug dockerised agent...` configurations as required (provided in `.vscode` subfolder). Attaching the `Python: Debug dockerised tests` debugger is required to start the tests, while attaching debuggers to both agents under tests are optional:

```bash
# Build and run dockerised agent tests in debug mode
bash run_debug_tests.sh
```

Running the integration tests, will create some forecast error plots in the [test_plots] repository for visual inspection (if wanted); however, these plots will automatically be deleted by the script after finishing all tests.


&nbsp;
# Authors #
Markus Hofmeister (mh807@cam.ac.uk), August 2023

Magnus Mueller (mm2692@cam.ac.uk), November 2022


<!-- Links -->
<!-- websites -->
[allows you to publish and install packages]: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-apache-maven-registry#authenticating-to-github-packages
[CMCL Docker registry wiki page]: https://github.com/cambridge-cares/TheWorldAvatar/wiki/Using-Docker-images
[py4jps]: https://pypi.org/project/py4jps/#description
[JPS_BASE_LIB]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB
[OntoTimeSeries]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_Ontology/ontology/ontotimeseries
[TimeSeriesClient]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/timeseries
[Darts]: https://unit8co.github.io/darts/index.html
[Prophet]: https://github.com/facebook/prophet
[Github container registry]: https://ghcr.io
[personal access token]: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
[Derived Information Framework]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/derivation
[Stack manager]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/Deploy/stacks/dynamic/stack-manager

<!-- files -->
[HTTP_Request_forecast]: ./resources/HTTP_request_forecast.http
[agent module]: ./forecasting/forecasting_agent/agent.py
[mapping file]: ./forecasting/datamodel/data_mapping.py
[docker-compose.debug.yml]: ./docker-compose.debug.yml
[docker-compose.test.yml]: ./docker-compose.test.yml
[docker compose file]: ./docker-compose.yml
[stack manager input config file]: ./stack-manager-input-config/forecasting-agent.json
[stack-manager-input-config]: ./stack-manager-input-config
[test_plots]: tests/test_plots/